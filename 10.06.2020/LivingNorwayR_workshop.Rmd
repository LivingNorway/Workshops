---
title: "LivingNorwayR_workshop"
author: "Matt"
date: "9 6 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#shiny::includeMarkdown
```

# Load the packages

```{r}
list.of.packages <- c("tidyverse", "devtools","readxl", "leaflet","collapsibleTree","sp", "uuid", "reshape2", "lubridate", "rworldmap")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

#devtools::install_github("LivingNorway/LivingNorwayR")
#devtools::install_github("LivingNorway/LivingNorwayData")
library(devtools)
library(LivingNorwayR)
library(LivingNorwayData)
library(tidyverse)
library(leaflet)
library(readxl)
library(collapsibleTree)

```

# Let's look at the functions in the LivingNorwayR package

```{r}
lsf.str("package:LivingNorwayR")

```

Currently we have 12 functions at various stages of development. 


# And the datasets in the LivingNorwayData package

```{r}
listdata<-ls("package:LivingNorwayData")
listdata

```

We have developed an R package dedicated to raw biodiversity data. At the moment there is `r length(listdata)` datasets in the raw biodiversity package. Here we will use the Rock ptarmigan dataset. 

```{r}
#?LivingNorwayData::Rock_ptarmigan
```


# LivingNorwayR

The R package associated with Living Norway, "LivingNorwayR" is currently in development, here we demonstrate the use of the first function which allows the user to  set up a logical folder structure in which to store all files associated with the data collected. This folder structure serves as the architecture for a "data package" which includes not only raw data, but digitised field notes, data that has been manipulated for analysis, analysis scripts, etc. In addition, data documentation such as data management plans and metadata should be included in the “data package”.

Not all projects will rely on the same underlying data flow model, but in our experience most field based ecology projects still have sufficient overlap in terms of data flow to make it worthwhile suggesting a common folder structure for field data projects. Beyond making it easier for the individual researchers or data management units to keep their data well organised, an important endpoint is to facilitate publication of the “data package” at the appropriate stage in the project lifecycle. Thus, the folder structure needs to facilitate publishing of the mapped data as a Darwin Core Archive (and preferentially register the data set with GBIF). Also the raw data could be easily extracted and archived in a generalist repository. 

## Creating your data package structure

We recommend working within an RStudio project so that you have more control about where your "working environment" is situated (this is folder where, on your computer, R saves files to). Once you have set-up a project (open RStudio select "File" then "New Project"), you can install and load LivingNorwayR (we have already done this above so we will not do this now). 


```{r install Living Norway}
#Install and load packages
# If you need to install packages first remove the "#" sign (which in R language means that the line is not run as code)
#install.packages(devtools)
#library(devtools)
#devtools::install_github("LivingNorway/LivingNorwayR")
#library(LivingNorwayR)
```


## Create the folder structure

The main function of the package is build_folder_structure() which takes an argument of the project_name. R does not like names to be too complex and to contain special characters or spaces. Please use "_" instead of a space in the project name (and in all your R work - it will make your life a lot easier). 


```{r folder structure, message=FALSE}
project_name="Rock_ptarmigan"
build_folder_structure(project_name = project_name)

```

Once you run the build_folder_structure() function you end up with a folder containing several sub-folders in your project. Let's explore these folders. 


```{r look at folders}
map_folders(project_name = "Rock_ptarmigan",addtable = "Yes", addPlot = "Yes")
```

From the tree diagram you can explore the folder structure (click on the blue nodes to expand them). At the moment we have 5 folders in the top-most heirachy: data, dmp,meta_xml,minimum_metadata and scripts. 

### data

The data folder contains three other folders: mapped_data, raw_data and scan_data. Let's start with the raw_data folder. In this folder you can place the data in its rawest form (i.e. no manipulation or data cleaning has taken place). Raw_data that you subsequently clean or transform in anyway needs to be stored in the mapped_data folder. It is really useful to be able to go back to the original data especially if something happens to the datafiles that you are working on for the analysis (the mapped_data file(s)). The scan_data folder contains scanned copies of non-digital raw data (field collection notes for example). 

### dmp

The dmp folder contains your data management plan. A data management plan is "a written document that describes the data you expect to acquire or generate during the course of a research project, how you will manage, describe, analyze, and store those data, and what mechanisms you will use at the end of your project to share and preserve your data" (https://library.stanford.edu/research/data-management-services/data-management-plans).


### meta_xml

This folder contains metadata in a machine readable form using the EML metadata language.


### scripts
Any code (e.g. python or R) used to manipulate the raw data, download publically available covariates, etc. should be saved in this folder. All scripts should be reproducilble by others not using your specifc computer (so not calling on locally stored files or functions). 

### Metadata
Metadata (a set of variables that describes the raw or transformed dataset) are required so that future users (including your future self) get an understanding of, for example, where the data was collected, who collected it and what units the variables were measured in. Basic mimimum metadata should be added as soon as possible (before you forget it). We will have a dedicated workshop focused on the metadata - but for now if you have any thoughts about what should be included in this file please let us know.

## Now we can add files to our folders

Here we add the raw data to the raw_data folder. We are using the ready_made dataset from the LivingNorwayData package. 

```{r}
dat<-LivingNorwayData::Rock_ptarmigan
saveRDS(dat, paste0(getwd(),"/",project_name,"/","data","/", "raw_data","/", "Rock_ptarmigan_dat.RDS"))
```

Let's also add some files to the other folders. We have not got any real data or files yet (please donate!) so we will just create some empty files with grand sounding names. 

```{r}
file.create(paste0(getwd(),"/",project_name,"/","dmp","/", "dmp.txt"))
file.create(paste0(getwd(),"/",project_name,"/","scripts","/", "A_brilliant_script.R"))
file.create(paste0(getwd(),"/",project_name,"/","data","/","scan_data","/", "scans_of_field_data_sheets.txt"))

```


## Functions that work with the raw data

### Geographic locations

```{r}
Rock_ptarmigan_dat <- readRDS(paste0(getwd(),"/",project_name,"/","data","/", "raw_data","/", "Rock_ptarmigan_dat.RDS"))
head(Rock_ptarmigan_dat)

```

```{r}
Rock_ptarmigan_dat %>% 
  names()

```

#### Challenge: commas not points in UTM coordinates

```{r}
Rock_ptarmigan_dat %>% 
  select(X.koordinat,Y.koordinat) %>% 
  head(2)

```

We need to conver the "," to "." using dplyr::mutate. We are changing the dataframe form the raw form so we should save this to the mapped_data folder. 

```{r}

df<-Rock_ptarmigan_dat
df<-df %>% 
  mutate(X.koordinat=gsub(",",".",X.koordinat)) %>%
  mutate(Y.koordinat=gsub(",",".",Y.koordinat))

saveRDS(df,paste0(getwd(),"/",project_name,"/","data","/","mapped_data","/", "mapped_data.RDS"))

```

```{r}
mapped_data <- readRDS(paste0(getwd(),"/",project_name,"/","data","/","mapped_data","/", "mapped_data.RDS"))

```


#### Challenge: Norway specific UTMs 

Using UTMs we need to convert them to Lat/Long to map using leaflet for example. Here I know the UTM code so we can convert it (see: https://epsg.io/?q=norway). How do we make this generic? 

```{r}
# I've had problems getting the leaflet package to load in the package - need to explore this behaviour

LivingNorwayR::get_NOR_geographic_extent(mapped_data, "X.koordinat", "Y.koordinat",Code = 3045)

```


### Get temporal coverage

#### Challenge: Date formats (link to function to test if the date coloumn is a date - if not convert to a date)

```{r}
LivingNorwayR::Check_date(mapped_data)# checks but doesnt convert

```


```{r}
mapped_data$Dato<-as.character.Date(mapped_data$Dato)
LivingNorwayR::get_temporal_cover(mapped_data$Dato)

```

### Map_files

We can look at the files in the data package using the 


```{r}
LivingNorwayR::map_files("Rock_ptarmigan", addtable = "Yes", addPlot = "Yes")
```



### Get taxonomic coverage

For this we need a different dataset 



```{r}
data_seapop<-LivingNorwayData::Seapop

```


```{r}
LivingNorwayR::get_taxa_cover(data=data_seapop,TaxaLevel = "species", TaxaField = "species", addFreq = "Yes", addPlot = "Yes")

```


## Mapping to Darwin Core

```{r}
library(sp)

library(uuid)

library(reshape2)

library(lubridate)

library(rworldmap)



d <-LivingNorwayData::Rock_ptarmigan




```

```{r}

#######################################################################################

#### ADDING GEOGRAPHIC CONTEXT TO THE DATA; 

### Transforming coordinates - from UTM W33 to log/lat

#### Assigning country to the points; 

d<-d %>% 
  mutate(X.koordinat=gsub(",",".",X.koordinat)) %>%
  mutate(Y.koordinat=gsub(",",".",Y.koordinat))

crs_temp33 <- CRS("+proj=utm +zone=34 +ellps=WGS84")

crs_temp_longlat <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")



coords <- data.frame(as.numeric(d$X.koordinat), as.numeric(d$Y.koordinat))


temp1 <- SpatialPoints(coords, proj4string=crs_temp33)

temp1 <- spTransform(temp1, crs_temp_longlat)
colnames(temp1@coords) <- c("decimalLongitude","decimalLatitude")



## Extracting info regarding country 

data(countriesLow)

test <- sp::over(temp1, countriesLow)


```

```{r}
##################

### Adding coordinateUncertaintyInMeters

### Adding geodeticDatum

### Adding locality

### Adding geodeticDatum

### adding country, countryID (ISO 3166-1 alfa-2) & locality (if occurence is in Norway)



d <- d %>% mutate(decimalLongitude=temp1$decimalLongitude, decimalLatitude=temp1$decimalLatitude,

                  geodeticDatum=paste("WGS84"),  

                  coordinateUncertaintyInMeters=ifelse(Plottsikkerhet==1, 20, 

                  ifelse(Plottsikkerhet==2, 500, 1000)), country=test$NAME, countryCode=test$ISO_A2, 

                  locality=ifelse(country=="Norway", "Indre Namdalen", ""))



```

```{r}
#############################################################

#### CONVERTING TIME-DATE OBJECTS TO ISO-STANDARDS; 

### Changing Date-format, using ISO 8601



d$eventDate <- as.Date(d$Dato, "%d.%m.%Y")



### Changing time format - terrible job becuase of strange format 



temp <- colsplit(d$Klokke, " ", c("date1", "time1"))

temp2 <- gsub(".", ':', temp$time1, fixed = T)

temp3 <- strptime(temp2 , "%H:%M:%S")

temp4 <- strftime(temp3, format="%H:%M")

d$eventTime <- paste(temp4, "CEST", sep=" ")

```


```{r}
###########################################################################################

### TRANSFORMING INFORAMTION THAT DOES NOT EASILY INTO dwc fields; 

### Constructing the dynamicProperties field

### event: two levels (capture OR radiotelemetry/recapture)

### state: three levels (alive OR dead (harvest) OR dead (non-harvest mortality))

### PUT TOGETHER IN RECORD: {event: ; state: }



### Could probably use r -> json package here; replace and explore

d <- d%>% mutate(event=ifelse(Status==2, "capture", "radiotelemetry/recapture"))

d <- d %>% mutate(state=ifelse(Status==0, "dead (harvest)", 

                               ifelse(Status==1 | Status==2, "alive", "dead (non-harvest mortality)")))

#d <- d %>% mutate(dynamicProperties=paste("{event:", event, "; state:", state, "}", sep=""))

d <- d %>% mutate(dynamicProperties=paste('{"event":', '"', event, '"', ',"state":', '"',state, '"',"}", sep=""))



```

```{r}

#########################################################################################

### AGE (juvenile: <365 days old, adult>366 days. 

### Age has to be recalculated, because in the raw data we only store age at capture



d <- d %>% mutate(Year=year(eventDate))

Date_Birth <- d %>% filter(Status==2) %>%

       select(Tagnr, Dato, Alder, Year) %>% 

       mutate(doB=ifelse(Alder==1, "2010-01-01", paste(Year-1, "06-01", sep="-"))) %>%

       select(Tagnr, doB) 



d <- left_join(d, Date_Birth)



d <- d %>% mutate(jul_event=julian(d$eventDate), jul_doB=julian(as.Date(d$doB)))

d <- d %>% mutate(age=julian(d$eventDate)-julian(as.Date(d$doB)))

d <- d %>% mutate(lifeStage=ifelse(age>365, "adult", "juvenile"))

```

```{r}
##########################################################################################

### Adding information about taxonomy; 

### This should be improved - to make sure consistency



d <- d %>% mutate(scientificName="Lagopus muta", kingdom="Animalia", phylum="Chordata", 

                  class="Aves", order="Galliformes", family="Tetraonidae", genus="Lagopus", 

                  taxonID="http://www.artsdatabanken.no/Taxon/3991")


```


```{r}
###########################################################################################

#### SOME ADDITINAL INFORMATION

### ownerInstitutionCode: Adding inforamiton about the data set/owner institution

### basisOfRecord: HumanObservation



d <- d %>% mutate(ownerInstitutionCode="NINA", basisOfRecord="HumanObservation",

                  sex=ifelse(d$Kjønn==1, "M", "F"))



### Renaming some columns

names(d)[names(d) == "Tagnr"] <- "organismName"

names(d)[names(d) == "Ving.1"] <- "Length_left_wing"

names(d)[names(d) == "Ving.2"] <- "Length_rigth_wing"

names(d)[names(d) == "Vekt"] <- "weigth"

names(d)[names(d) == "Bryst"] <- "Length_sternum"


```

```{r}
###########################################################################################

#### PREPARING & FINALIZING THE OCCURENCE TABLE: 



Occurrence_dat <- d[,c("organismID", "organismName","occurrenceID", "sex", "lifeStage", "eventDate", "eventTime", 

                       "basisOfRecord", "dynamicProperties", "scientificName", "kingdom",

                       "phylum", "class", "order", "family", "genus", "taxonID", "decimalLatitude",

                       "decimalLongitude", "geodeticDatum", "coordinateUncertaintyInMeters",

                       "country", "countryCode", "locality", "ownerInstitutionCode")]





```

```{r}

############################################################################################

##### PREPARING MEASURMENT AND FACTS TABLE



MM <- d %>% filter(Status==2)



MM <- MM[,c("organismID", "organismName", "occurrenceID", 

          "Length_left_wing", "Length_rigth_wing", "weigth", "Length_sternum")]



MM <- reshape(MM, timevar="measurementType", 

                varying=c("Length_left_wing", "Length_rigth_wing", "weigth", "Length_sternum"),

                times=c("Length_left_wing", "Length_rigth_wing", "weigth", "Length_sternum"),

                v.names = "measurementValue",

                direction="long")



rownames(MM) <- NULL

MM <- MM %>% mutate(measurementUnit=ifelse(measurementType=="weigth", "g", "mm"))

MM$id <- NULL

MM <- drop_na(MM)

MM <- MM %>%
  mutate(measurementValue=gsub(",",".", measurementValue) )%>% 
  mutate(measurementValue=as.numeric(measurementValue)) %>% 
    mutate(measurementValue=round(measurementValue,0))

MM <- MM[,c("occurrenceID", "organismID", "organismName", "measurementValue", "measurementType", "measurementUnit")]

```

```{r}

###########################################################################################

#### WRITING THE FILES; 

## Occurence_data 

## Measurement_and_Facts_data



#write.table(Occurrence_dat, "RockPtarmiganExample/Occurrence_data.txt", row.names = FALSE, col.names=TRUE, sep="\t", quote = FALSE)

#write.table(MM, "RockPtarmiganExample/Measurement_and_Facts_data.txt", row.names = FALSE, col.names=TRUE, sep="\t")





#### WOrkflow - component; 

## Need to use a validater at this point

```


